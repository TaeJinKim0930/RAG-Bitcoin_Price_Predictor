import os
import json
from dotenv import load_dotenv

import streamlit as st

# í¬ë¡¤ë§
import requests
from bs4 import BeautifulSoup
from langchain_core.documents import Document

# LangChain Core
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document

# LangChain-OpenAI
from langchain_openai import ChatOpenAI

# Tavily ê²€ìƒ‰ ë„êµ¬
from langchain_community.tools.tavily_search import TavilySearchResults

# --- í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ---
load_dotenv()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="ğŸ’° ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ ì±—ë´‡")
st.title("ğŸ’° RAG ê¸°ë°˜ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ ì±—ë´‡ \n ex) 2025ë…„ 4ì›” í•œë‹¬ê°„ì˜ ë°ì´í„°ë¥¼ ë´¤ì„ ì‹œ 5ì›”ë‹¬ ë¹„íŠ¸ì½”ì¸ì˜ ê°€ê²© ì „ë§ì€ ì–´ë–»ê²Œ ë ê¹Œ")

# --- ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ---
if "history" not in st.session_state:
    st.session_state.history = []

# --- Tavily ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ---
search_tool = TavilySearchResults(api_key=TAVILY_API_KEY)

def search_docs(query: str, k: int = 30) -> list[Document]:
    # Tavily ê²€ìƒ‰ ê²°ê³¼
    results = search_tool.invoke(query)
    tavily_docs = [
        Document(page_content=entry["content"], metadata={"source": entry["url"]})
        for entry in results[:k]
    ]

    # mempool.space í¬ë¡¤ë§ ê²°ê³¼
    title, content, url = crawl_mempool_space()
    mempool_doc = Document(page_content=content, metadata={"source": url, "title": title})

    # ë‘ ê²°ê³¼ í•©ì³ì„œ ë°˜í™˜
    return tavily_docs + [mempool_doc]

# --- ë¸”ë¡ì²´ì¸ mempool ---
def crawl_mempool_space():
    try:
        url = "https://mempool.space/"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")

        # ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì¶”ì¶œ (ì˜ˆì‹œ)
        price_element = soup.find("span", class_="text-xl font-bold")  # í´ë˜ìŠ¤ëª… í™•ì¸ í•„ìš”
        price = price_element.text.strip() if price_element else "N/A"

        # ë¸”ë¡ ì •ë³´ ì¶”ì¶œ (ì˜ˆì‹œ)
        block_height_element = soup.find("a", {"href": lambda href: href and href.startswith("/block/")})
        block_height = block_height_element.text.strip() if block_height_element else "N/A"

        # êµ¬ê¸€ì—ì„œ ë¹„íŠ¸ì½”ì¸ ê°€ê²© í¬ë¡¤ë§
        google_price = crawl_google_bitcoin_price()

        # ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ ë¹„íŠ¸ì½”ì¸ ê±°ë˜ëŸ‰ í¬ë¡¤ë§
        volume = crawl_coinmarketcap_volume()

        # ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ ë¹„íŠ¸ì½”ì¸ RSI í¬ë¡¤ë§
        rsi = crawl_coinmarketcap_rsi()

        content = f"í˜„ì¬ ë¹„íŠ¸ì½”ì¸ ê°€ê²©: {price}, ìµœì‹  ë¸”ë¡ ë†’ì´: {block_height}, êµ¬ê¸€ì—ì„œ í¬ë¡¤ë§í•œ ê°€ê²©: {google_price}, ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ 24ì‹œê°„ ê±°ë˜ëŸ‰: {volume}, ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ RSI: {rsi}"
        return "Bitcoin Information", content, url
    except Exception as e:
        print(f"Error crawling mempool.space: {e}")
        return "Error", "Could not retrieve Bitcoin information.", ""

# --- êµ¬ê¸€ì—ì„œ ë¹„íŠ¸ì½”ì¸ ê°€ê²© í¬ë¡¤ë§ ---
def crawl_google_bitcoin_price():
    try:
        url = "https://www.google.com/search?q=bitcoin+price"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")

        # ì˜ˆì¸¡ ê°€ê²© ë²”ìœ„ ì •ë³´ê°€ í‘œì‹œë˜ëŠ” ìš”ì†Œ ì°¾ê¸°
        range_element = soup.find("div", class_="range")  # ì‹¤ì œ í´ë˜ìŠ¤ëª… í™•ì¸ í•„ìš”
        if range_element:
            min_price, max_price = range_element.text.split("-")  # ë²”ìœ„ ë¬¸ìì—´ íŒŒì‹±
            min_price = min_price.strip()
            max_price = max_price.strip()
        else:
            min_price = "N/A"
            max_price = "N/A"

        return price, min_price, max_price  # ì„¸ ê°€ì§€ ê°’ ë°˜í™˜
    except Exception as e:
        print(f"Error crawling Google for Bitcoin price: {e}")
        return "N/A"

# --- ì½”ì¸ë§ˆì¼“ ìº¡ì—ì„œì˜ ë¹„íŠ¸ì½”ì¸ ê±°ë˜ëŸ‰ í¬ë¡¤ë§
def crawl_coinmarketcap_volume():
    try:
        url = "https://coinmarketcap.com/currencies/bitcoin/"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")

        # ê±°ë˜ëŸ‰ ì •ë³´ê°€ í‘œì‹œë˜ëŠ” ìš”ì†Œ ì°¾ê¸° (ì˜ˆì‹œ - ìµœì‹  ì›¹ í˜ì´ì§€ êµ¬ì¡° í™•ì¸ í•„ìš”)
        volume_element = soup.find("div", class_="statsValue___2iaoZ")  # í´ë˜ìŠ¤ëª… í™•ì¸ í•„ìš”
        if volume_element:
            volume = volume_element.text.strip()
        else:
            volume = "N/A"  # ê±°ë˜ëŸ‰ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°

        return volume
    except Exception as e:
        print(f"Error crawling CoinMarketCap for volume: {e}")
        return "N/A"

# --- ì½”ì¸ë§ˆì¼“ ìº¡ì—ì„œ ë¹„íŠ¸ì½”ì¸ rsi í¬ë¡¤ë§
def crawl_coinmarketcap_rsi():
    try:
        url = "https://coinmarketcap.com/currencies/bitcoin/technical-indicators/"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, "html.parser")

        # RSI ì •ë³´ê°€ í‘œì‹œë˜ëŠ” ìš”ì†Œ ì°¾ê¸° (ì˜ˆì‹œ - ìµœì‹  ì›¹ í˜ì´ì§€ êµ¬ì¡° í™•ì¸ í•„ìš”)
        rsi_element = soup.find("span", string="RSI")  # RSI í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ìš”ì†Œ ì°¾ê¸°
        if rsi_element:
            rsi_value = rsi_element.find_next("span").text.strip()  # RSI ê°’ ì¶”ì¶œ
        else:
            rsi_value = "N/A"  # RSI ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°

        return rsi_value
    except Exception as e:
        print(f"Error crawling CoinMarketCap for RSI: {e}")
        return "N/A"


# --- Prompt í…œí”Œë¦¿ ì •ì˜ ---
prompt = PromptTemplate.from_template(
    """ì´ì „ ëŒ€í™”:
{chat_history}

ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ, ì•„ë˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ê³  ì¶œì²˜(URL)ë¥¼ í•¨ê»˜ ì¸ìš©í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ê´€ë ¨ ì§ˆë¬¸ì€ ì•„ë˜ "Bitcoin Information" ë¬¸ë§¥ì„ **ë°˜ë“œì‹œ** ì°¸ì¡°í•˜ê³ , 
ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œë“¤ì„ **ëª¨ë‘ í¬í•¨**í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
ê°€ê²©ì„ ë§í•´ ì¤„ ë•ŒëŠ” í•­ìƒ ë‹¬ëŸ¬($) ê¸°ì¤€ìœ¼ë¡œ ë§í•´ì£¼ê³  ê°€ê²© ì•ì— $ ì‚¬ì¸ì„ í•­ìƒ ë¶™ì—¬ì¤˜ì„œ ì‚¬ëŒë“¤ì´ ì–´ë–¤ ëˆì˜ ê¸°ì¤€ì¸ì§€ ì•Œ ìˆ˜ ìˆê²Œ í•´ì¤˜

## ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ ì •ë³´:

* **í˜„ì¬ êµ¬ê¸€ë§í•œ ë¯¸êµ­ ì£¼ì‹ì‹œì¥ ê¸°ì¤€ ë¹„íŠ¸ì½”ì¸ ê°€ê²©:** í˜„ì¬ êµ¬ê¸€ ê¸°ì¤€ ë¹„íŠ¸ì½”ì¸ì˜ ê°€ê²©ì…ë‹ˆë‹¤: ${google_price} ë‹¬ëŸ¬
* **ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ 24ì‹œê°„ ê±°ë˜ëŸ‰:** ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ 24ì‹œê°„ ê±°ë˜ëŸ‰ ì •ë³´ì…ë‹ˆë‹¤: ${coinmarketcap_stat}.
* **ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ RSI:** ì½”ì¸ë§ˆì¼“ìº¡ì—ì„œ í¬ë¡¤ë§í•œ RSI ì •ë³´ì…ë‹ˆë‹¤: ${coinmarketcap_rsi}

## ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ì— ê³ ë ¤í•´ì•¼ í•  ìš”ì†Œ:

**ë‹¤ìŒ ìˆœì„œëŒ€ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.**

1. **ì„  ìš”ì•½:** ë‹¤ìŒ ë‹¬ ë¹„íŠ¸ì½”ì¸ì˜ ê°€ê²©ì€ ì˜¤ëŠ˜ë³´ë‹¤ ì˜¤ë¥¼ ê²ƒ/ë‚´ë¦´ ê²ƒ ì…ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
2. **ê³µê¸‰ê³¼ ìˆ˜ìš”:** ë¹„íŠ¸ì½”ì¸ì˜ ë°œí–‰ëŸ‰ì€ ì œí•œë˜ì–´ ìˆìœ¼ë©°, ìˆ˜ìš” ë³€í™”ì— ë”°ë¼ ê°€ê²©ì´ ì˜í–¥ì„ ë°›ìŠµë‹ˆë‹¤. 
    * ì˜ˆì‹œ: ìµœê·¼ ë¹„íŠ¸ì½”ì¸ì— ëŒ€í•œ ê¸°ê´€ íˆ¬ììë“¤ì˜ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆì–´ ê°€ê²©ì´ ìƒìŠ¹í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.
3. **ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©:** ì„¸ê³„ ê²½ì œ ìƒí™©, ì¸í”Œë ˆì´ì…˜, ê¸ˆë¦¬ ë“± ê±°ì‹œê²½ì œ ìš”ì¸ì´ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * ì˜ˆì‹œ: í˜„ì¬ ë¯¸êµ­ ì—°ì¤€ì˜ ê¸ˆë¦¬ ì¸ìƒ ì •ì±…ìœ¼ë¡œ ì¸í•´ íˆ¬ì ì‹¬ë¦¬ê°€ ìœ„ì¶•ë˜ì–´ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ í•˜ë½í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
4. **ê·œì œ ë³€í™”:** ê°êµ­ì˜ ì•”í˜¸í™”í ê·œì œ ì •ì±… ë³€í™”ëŠ” ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
    * ì˜ˆì‹œ: ì¤‘êµ­ ì •ë¶€ì˜ ì•”í˜¸í™”í ê±°ë˜ ê¸ˆì§€ ì •ì±…ìœ¼ë¡œ ì¸í•´ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ ê¸‰ë½í•œ ì‚¬ë¡€ê°€ ìˆìŠµë‹ˆë‹¤.
5. **ì‹œì¥ ì‹¬ë¦¬:** íˆ¬ììë“¤ì˜ ì‹¬ë¦¬ì™€ ê¸°ëŒ€ê°ì€ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë³€ë™ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
    * ì˜ˆì‹œ: ì¼ë¡  ë¨¸ìŠ¤í¬ì˜ íŠ¸ìœ— í•˜ë‚˜ë¡œ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ í¬ê²Œ ë³€ë™í•˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤.
6. **ê¸°ìˆ ì  ë¶„ì„:** ì°¨íŠ¸ íŒ¨í„´, ê±°ë˜ëŸ‰, ì´ë™ í‰ê· ì„  ë“± ê¸°ìˆ ì  ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ ê°€ê²© ë³€ë™ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * ì˜ˆì‹œ: ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ 200ì¼ ì´ë™ í‰ê· ì„ ì„ ìƒí–¥ ëŒíŒŒí•˜ë©´ ê°•ì„¸ì¥ìœ¼ë¡œ ì „í™˜ë  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
7. **ì „ìŸ ë° ì •ì¹˜ì  ë¶ˆì•ˆì •:** ì‹¤ì œë¡œ ì¼ì–´ë‚˜ëŠ” ì „ìŸ, ë¬´ì—­ ì „ìŸ, êµ­ê°€ ê°„ì˜ ì •ì¹˜ì  ê°ˆë“± ë“±ìœ¼ë¡œ ì¸í•œ í™”í ê°€ì¹˜ì˜ ë³€í™” ë“±ì´ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
    * ì˜ˆì‹œ: ëŸ¬ì‹œì•„-ìš°í¬ë¼ì´ë‚˜ ì „ìŸìœ¼ë¡œ ì¸í•´ ì•ˆì „ ìì‚° ì„ í˜¸ í˜„ìƒì´ ê°•í•´ì§€ë©´ì„œ ê¸ˆê³¼ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤.
8. **ê²°ë¡ :** ìœ„ì™€ ê°™ì€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¬ ë¹„íŠ¸ì½”ì¸ì˜ ê°€ê²©ì€ í˜„ì¬ ê¸°ì¤€ì—ì„œ ì˜¤ë¥¸ë‹¤ë©´/ë‚´ë¦°ë‹¤ë©´ ìµœì € $ {min_price} ë‹¬ëŸ¬ì—ì„œ ìµœëŒ€ $ {max_price} ë‹¬ëŸ¬ë¡œ ì˜¤ë¥¼ ê²ƒ/ë‚´ë¦´ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. 


## ì¶”ê°€ ì •ë³´:

* ì˜ˆì¸¡ì€ ì°¸ê³ ìš©ì´ë©°, íˆ¬ì ê²°ì •ì— ëŒ€í•œ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.
* ì•”í˜¸í™”í ì‹œì¥ì€ ë³€ë™ì„±ì´ ë§¤ìš° í¬ë¯€ë¡œ, íˆ¬ì ì‹œ ì‹ ì¤‘í•˜ê²Œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.


ë¬¸ë§¥:
{context}

ì§ˆë¬¸:
{question}
"""
)

# --- OpenAI LLM ì„¤ì • ---
llm = ChatOpenAI(model="gpt-4.1-mini", api_key=OPENAI_API_KEY)

# --- RAG ì²´ì¸ êµ¬ì„± ---
def format_docs(docs: list[Document]) -> str:
    return "\n\n".join(doc.page_content for doc in docs)

web_rag_chain = (
    {
        "context": lambda x: format_docs(search_docs(x["question"])),
        "question": RunnablePassthrough(),
        "chat_history": RunnablePassthrough(),
        "google_price": lambda x: crawl_google_bitcoin_price()[0],  # êµ¬ê¸€ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì¶”ê°€,
        "coinmarketcap_stat": lambda x: crawl_coinmarketcap_volume(), # ì½”ì¸ë§ˆì¼“ìº¡ ë¹„íŠ¸ì½”ì¸ ê±°ë˜ëŸ‰ ì¶”ê°€ 
        "coinmarketcap_rsi": lambda x: crawl_coinmarketcap_rsi(), # ì½”ì¸ë§ˆì¼“ìº¡ ë¹„íŠ¸ì½”ì¸ rsi ì¶”ê°€ 
        "min_price": lambda x: crawl_google_bitcoin_price()[1],  # ìµœì € ê°€ê²©
        "max_price": lambda x: crawl_google_bitcoin_price()[2]   # ìµœê³  ê°€ê²©
    }
    | prompt
    | llm
    | StrOutputParser()
)

# --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ì˜ì—­ ---
st.markdown("## ëŒ€í™” ê¸°ë¡")
for entry in st.session_state.history:
    if entry["role"] == "user":
        st.markdown(f"**You:** {entry['message']}")
    else:
        st.markdown(f"**Bot:** {entry['message']}")
st.markdown("---")

# --- ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ë° ì²˜ë¦¬ ---
question = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if question:
    # 1) ì„¸ì…˜ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.history.append({"role": "user", "message": question})

    # 2) Tavily ë¬¸ì„œ ê²€ìƒ‰ + RAG ì‘ë‹µ ìƒì„±
    docs = search_docs(question)
    answer = web_rag_chain.invoke({"question": question, "chat_history": st.session_state.history})

    # 3) ì„¸ì…˜ì— ë´‡ ì‘ë‹µ ì €ì¥
    st.session_state.history.append({"role": "bot", "message": answer})

    # 4) ëŒ€í™” ê¸°ë¡ íŒŒì¼ë¡œ ì˜êµ¬ ì €ì¥
    with open("history.json", "w", encoding="utf-8") as f:
        json.dump(st.session_state.history, f, ensure_ascii=False, indent=2)

    # 5) ì‘ë‹µ ë° ì¶œì²˜ ì¶œë ¥
    sources = "\n".join(f"- {doc.metadata['source']}" for doc in docs)
    st.markdown(answer + "\n\n---\n**ğŸ”— ì¶œì²˜**\n" + sources)
